{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6669,"sourceType":"datasetVersion","datasetId":4318}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install torchensemble\n!pip install facenet-pytorch\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-02T09:01:35.263223Z","iopub.execute_input":"2023-12-02T09:01:35.263600Z","iopub.status.idle":"2023-12-02T09:01:59.091836Z","shell.execute_reply.started":"2023-12-02T09:01:35.263569Z","shell.execute_reply":"2023-12-02T09:01:59.090544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nfrom sklearn.model_selection import train_test_split\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\nfrom tempfile import TemporaryDirectory\nfrom facenet_pytorch import InceptionResnetV1\nimport copy\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:01:59.094682Z","iopub.execute_input":"2023-12-02T09:01:59.095127Z","iopub.status.idle":"2023-12-02T09:01:59.103967Z","shell.execute_reply.started":"2023-12-02T09:01:59.095081Z","shell.execute_reply":"2023-12-02T09:01:59.102883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using AlexNet we will aim to train classifier of celebrities\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        #transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:27:03.211243Z","iopub.execute_input":"2023-12-02T09:27:03.211653Z","iopub.status.idle":"2023-12-02T09:27:03.219725Z","shell.execute_reply.started":"2023-12-02T09:27:03.211617Z","shell.execute_reply":"2023-12-02T09:27:03.218579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/5-celebrity-faces-dataset'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n#load data\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:27:07.090157Z","iopub.execute_input":"2023-12-02T09:27:07.091091Z","iopub.status.idle":"2023-12-02T09:27:07.109577Z","shell.execute_reply.started":"2023-12-02T09:27:07.091055Z","shell.execute_reply":"2023-12-02T09:27:07.108479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data visualisation\ndef imshow(inp, title=None):\n    \"\"\"Display image for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:27:07.505463Z","iopub.execute_input":"2023-12-02T09:27:07.505850Z","iopub.status.idle":"2023-12-02T09:27:08.401836Z","shell.execute_reply.started":"2023-12-02T09:27:07.505817Z","shell.execute_reply":"2023-12-02T09:27:08.400919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model training\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n    \n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:28:35.371900Z","iopub.execute_input":"2023-12-02T09:28:35.372339Z","iopub.status.idle":"2023-12-02T09:28:35.386936Z","shell.execute_reply.started":"2023-12-02T09:28:35.372297Z","shell.execute_reply":"2023-12-02T09:28:35.385670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:28:35.534812Z","iopub.execute_input":"2023-12-02T09:28:35.535225Z","iopub.status.idle":"2023-12-02T09:28:35.544203Z","shell.execute_reply.started":"2023-12-02T09:28:35.535192Z","shell.execute_reply":"2023-12-02T09:28:35.543120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load model and freeze all except the final layer\nmodel_conv = torchvision.models.vit_l_32(weights='IMAGENET1K_V1')\n#Parameters of newly constructed modules have requires_grad=True by default\n#print(model_conv)\nfor param in model_conv.parameters():    \n    param.requires_grad = False\nnum_ftrs = model_conv.heads[-1].in_features\nmodel_conv.heads[-1] = nn.Linear(num_ftrs, 5)\nmodel_conv = model_conv.to(device)\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer_conv = optim.Adam(model_conv.heads[-1].parameters(), lr=0.005)\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer_conv,T_0 = 8,# Number of iterations for the first restart\n                                        T_mult = 1, # A factor increases TiTiâ€‹ after a restart\n                                        eta_min = 1e-4)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:38:23.869872Z","iopub.execute_input":"2023-12-02T10:38:23.870657Z","iopub.status.idle":"2023-12-02T10:38:28.057186Z","shell.execute_reply.started":"2023-12-02T10:38:23.870616Z","shell.execute_reply":"2023-12-02T10:38:28.056331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler,\n                       num_epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:45:55.395432Z","iopub.execute_input":"2023-12-02T10:45:55.396147Z","iopub.status.idle":"2023-12-02T10:50:28.762491Z","shell.execute_reply.started":"2023-12-02T10:45:55.396110Z","shell.execute_reply":"2023-12-02T10:50:28.761145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\n\nclass MyEnsembleModel(nn.Module):\n    def __init__(self, model_1, model_2):\n        super().__init__()\n        self.model_1 = model_1\n        self.model_2 = model_2\n        # Remove last linear layer from both models:\n        self.model_1.fc = nn.Identity()\n        self.model_2.fc = nn.Identity()\n\n        # Add a new linear layer:\n        # we are adding up the output logits in the forward pass, \n        # hence keeping 2048, which is the number of in_features to both resnet and inception\n        self.fc = nn.Linear(2048, 6) # output of 6 dimensional logits\n\n    def forward(self, x):\n        x1 = self.model_1(x.clone())\n        # the output of inceptionv3 is InceptionOutputs class, a tuple with .logits and .auxlogits,\n        # taking the logits tensor \n        x2 = self.model_2(x)[0]\n        # adding the outputs of the 2 models \n        x = x1 + x2\n        # return x with output of the new linear layer (6 classes)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:02:00.921377Z","iopub.status.idle":"2023-12-02T09:02:00.921720Z","shell.execute_reply.started":"2023-12-02T09:02:00.921543Z","shell.execute_reply":"2023-12-02T09:02:00.921558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model_conv)\n\nplt.ioff()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model_predictions(model,img_path):\n    was_training = model.training\n    model.eval()\n\n    img = Image.open(img_path)\n    img = data_transforms['val'](img)\n    img = img.unsqueeze(0)\n    img = img.to(device)\n\n    with torch.no_grad():\n        outputs = model(img)\n        _, preds = torch.max(outputs, 1)\n\n        ax = plt.subplot(2,2,1)\n        ax.axis('off')\n        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n        imshow(img.cpu().data[0])\n        \n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T10:41:09.596987Z","iopub.execute_input":"2023-12-02T10:41:09.597486Z","iopub.status.idle":"2023-12-02T10:41:09.605233Z","shell.execute_reply.started":"2023-12-02T10:41:09.597441Z","shell.execute_reply":"2023-12-02T10:41:09.604360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}